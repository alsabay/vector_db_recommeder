{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1204dd4-0e20-47a1-9df1-9d796b16f7f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#conda install -q -c conda-forge gensim faiss-gpu -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "959d8a17",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture _messages\n",
    "\n",
    "import pandas as pd\n",
    "import gensim.downloader as api\n",
    "from gensim.models import Word2Vec\n",
    "import re\n",
    "\n",
    "# Load the pre-trained Word2Vec model or train your own on the dataset.\n",
    "print(\"Loading Word2Vec model...\")\n",
    "model = api.load('word2vec-google-news-300')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bded68-8132-43dc-9f24-86f41b507000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Load the Movies_dataset.csv using pandas.\n",
    "df = pd.read_csv('./data/Movies_dataset.csv')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove non-alphanumeric characters and convert to lowercase.\n",
    "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text.lower())\n",
    "    return text\n",
    "\n",
    "# Apply the preprocessing to the 'Movie_Name' column.\n",
    "df['title_cleaned'] = df['Movie_Name'].apply(preprocess_text)\n",
    "\n",
    "# Remove duplicates (if any) based on the 'title_cleaned' column.\n",
    "df = df.drop_duplicates(subset='title_cleaned', keep='first')\n",
    "\n",
    "# Extract the cleaned movie titles from the DataFrame.\n",
    "movies = df['title_cleaned'].tolist()\n",
    "\n",
    "# Function to convert item names to vectors using the Word2Vec model.\n",
    "def item_name_to_vector(item_name):\n",
    "    try:\n",
    "        return model[item_name]\n",
    "    except KeyError:\n",
    "        #print(f\"Item '{item_name}' not found in the Word2Vec vocabulary.\")\n",
    "        return None\n",
    "\n",
    "# Create a dictionary to store item vectors.\n",
    "item_vectors = {item: item_name_to_vector(item) for item in movies}\n",
    "\n",
    "# Remove items with no corresponding vectors (not in the Word2Vec vocabulary).\n",
    "item_vectors = {item: vector for item, vector in item_vectors.items() if vector is not None}\n",
    "\n",
    "# Display the number of items with valid vectors.\n",
    "print(f\"Number of items with valid vectors: {len(item_vectors)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1147e3e6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set up Faiss db\n",
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "# Convert item vectors to a NumPy array for Faiss indexing.\n",
    "item_vector_array = [vector for vector in item_vectors.values()]\n",
    "item_vector_array = [vector.tolist() for vector in item_vector_array]\n",
    "\n",
    "# Convert the list of lists into a 2D NumPy array.\n",
    "item_vector_array = np.array(item_vector_array, dtype='float32')\n",
    "\n",
    "# Initialize a Faiss index.\n",
    "index = faiss.IndexFlatL2(model.vector_size)\n",
    "\n",
    "# Add the item vectors to the index.\n",
    "index.add(item_vector_array)\n",
    "\n",
    "# Save the index to a file for future use.\n",
    "faiss.write_index(index, './data/movie_index.faiss')\n",
    "\n",
    "# lets look at the index keys\n",
    "print(item_vectors.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697ed71f-a0c6-460c-9327-2aeb4ab7a111",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# input user preferences\n",
    "\n",
    "# Assuming you have loaded the Faiss index and item_vectors dictionary (as shown in the previous steps).\n",
    "\n",
    "# Function to get user input and find similar items.\n",
    "def find_similar_items(user_input, k=5):\n",
    "    # Preprocess the user input to match the format of item names in 'item_vectors'.\n",
    "    preprocessed_input = preprocess_text(user_input)\n",
    "    \n",
    "    # Get the vector representation of the user input.\n",
    "    input_vector = item_name_to_vector(preprocessed_input)\n",
    "    \n",
    "    if input_vector is not None:\n",
    "        # Convert the input vector to a 2D NumPy array.\n",
    "        input_vector = np.array([input_vector], dtype='float32')\n",
    "\n",
    "        # Perform similarity search using the Faiss index.\n",
    "        _, indices = index.search(input_vector, k+1)  # +1 to exclude the input item itself from recommendations.\n",
    "        \n",
    "        # Get the names of the similar items.\n",
    "        similar_items = [list(item_vectors.keys())[i] for i in indices[0]]\n",
    "        \n",
    "        # Exclude the input item from the recommendations.\n",
    "        similar_items = [item for item in similar_items if item != preprocessed_input]\n",
    "        \n",
    "        # Display the top-k similar items.\n",
    "        print(f\"Top-{k} recommendations for '{user_input}':\")\n",
    "        for i, item in enumerate(similar_items[:k], 1):\n",
    "            print(f\"{i}. {item}\")\n",
    "    else:\n",
    "        print(\"Item not found or not valid. Please try again.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58190ead-0aae-4272-a12e-0679fb6e66da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Sample usage:\n",
    "user_input = input(\"Enter your preference or interest: \")\n",
    "find_similar_items(user_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deac320",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we can add user profiles to the recommendation system to make it more personalized. \n",
    "# The user profiles allow users to build a history of liked items, and we can use this \n",
    "# information to improve the recommendations.\n",
    "\n",
    "# Initialize an empty user profile dictionary to store liked items for each user.\n",
    "user_profiles = {}\n",
    "\n",
    "# Function to add items to a user's profile.\n",
    "def add_item_to_profile(user_id, item_name):\n",
    "    if user_id in user_profiles:\n",
    "        user_profiles[user_id].append(item_name)\n",
    "    else:\n",
    "        user_profiles[user_id] = [item_name]\n",
    "\n",
    "# Function to get user recommendations based on their profile.\n",
    "def get_user_recommendations(user_id, k=5):\n",
    "    if user_id in user_profiles:\n",
    "        liked_items = user_profiles[user_id]\n",
    "        \n",
    "        # Convert the user's liked items to vectors.\n",
    "        liked_vectors = [item_name_to_vector(item) for item in liked_items]\n",
    "        liked_vectors = np.array([vector for vector in liked_vectors if vector is not None], dtype='float32')\n",
    "        \n",
    "        if len(liked_vectors) > 0:\n",
    "            # Compute the average vector for the user's liked items.\n",
    "            user_vector = np.mean(liked_vectors, axis=0)\n",
    "            \n",
    "            # Convert the user vector to a 2D NumPy array.\n",
    "            user_vector = np.array([user_vector], dtype='float32')\n",
    "            \n",
    "            # Perform similarity search using the Faiss index.\n",
    "            _, indices = index.search(user_vector, k)\n",
    "            \n",
    "            # Get the names of the similar items.\n",
    "            similar_items = [list(item_vectors.keys())[i] for i in indices[0]]\n",
    "            \n",
    "            # Exclude items that are already in the user's profile.\n",
    "            recommended_items = [item for item in similar_items if item not in liked_items]\n",
    "            \n",
    "            # Display the recommendations.\n",
    "            print(f\"Top-{k} recommendations for User {user_id}:\")\n",
    "            for i, item in enumerate(recommended_items, 1):\n",
    "                print(f\"{i}. {item}\")\n",
    "        else:\n",
    "            print(f\"User {user_id} has no liked items.\")\n",
    "    else:\n",
    "        print(f\"User {user_id} not found. Please add liked items to the user profile first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61d1953-90af-4275-a3d9-74029ffc2a21",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Movie Recommendations by UserID Demo\n",
    "\n",
    "user_id = input(\"UserID? <enter number>\")\n",
    "items = input(\"Enter item or items that you liked: \")\n",
    "liked_items = items.split()\n",
    "\n",
    "for item in liked_items:\n",
    "    # Ensure the item exists in 'item_vectors' before adding it to the user's profile.\n",
    "    if item in item_vectors:\n",
    "        add_item_to_profile(user_id, item)\n",
    "#print(user_profiles)\n",
    "\n",
    "# list recommendation for the user\n",
    "get_user_recommendations(user_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34596675-0c8a-4bf3-be7c-0f7638bff448",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
